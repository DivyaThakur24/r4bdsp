[
["index.html", "R for the Bertelsmann Data Science Scholarship Program Welcome", " R for the Bertelsmann Data Science Scholarship Program TBD Welcome This is the website for “R for the Bertelsmann Data Science scholarship Program”. This book will be an R-based supplemental resource for those participating in the Bertelsmann Data Science Scholarship Program. It will contain sections of the curriculum translated into R and also supplemental tutorials on specific topics using R. "],
["sql-intro.html", "1 Introduction", " 1 Introduction This portion of the book focuses on translating Lessons 28-32 of the Bertelsmann Data Science Scholarship Program. These lessons provide the foundation for working with databases using Structured Query Language (SQL). Like the lessons within the scholarship program, we will using data from the fictional Parch and Posey company. You can access this data by installing the parchposey package from GitHub: devtools::install_github(&quot;jdbarillas/parchposey&quot;) You will learn how to recreate the analyses in R using the dplyr package from the tidyverse in the following ways: dplyr provides a set of verbs that are combined to solve data manipulation problems. "],
["topics-intro.html", "2 Introduction", " 2 Introduction This part of the book provides tutorials on specific topics using R. These tutorials are written and curated by scholarship participants. We will be using a shared repository model. Therefore, you can contribute to the book by following these steps: Clone the book repo from GitHub. Create a separate branch for your topic Add the file(s) to the proper directories and commit the changes to your topic branch Push the changes to GitHub and submit a pull request For information on the shared repository model, see here and here. "],
["jolynn.html", "3 Jolynn 3.1 Lesson 2 Visualization 3.2 Lesson 4 Variability 3.3 Lesson 6 Normal Distribution", " 3 Jolynn Bio/Motivation/Social Handles 3.1 Lesson 2 Visualization In this exercise we will start by looking at the characteristics of our dataset. All definitions and data come from the original Udacity lesson and can be found here. 3.1.1 Data We start by assigning our data to Petals, a list of petal counts from flowers. Petals &lt;- c(15, 16, 17, 16, 21, 22, 15, 16, 15, 17, 16, 22, 14, 13, 14, 14, 15, 15, 14, 15, 16, 10, 19, 15, 15, 22, 24, 25, 15, 16) 3.1.2 Frequency The frequency of a data set is the number of times a certain outcome occurs. # Find the most frequent petal count. # to do this we create a table from Petals, sort it in decreasing order, and get the name of the first item. MostFreq &lt;- names(sort(table(Petals),decreasing=TRUE)[1]) print(paste0(&quot;The most frequent petal count is: &quot;, MostFreq)) ## [1] &quot;The most frequent petal count is: 15&quot; # Find the frequency of flowers with 15 petals. # We can use the same method as above but without the names PetalFreq &lt;- sort(table(Petals),decreasing=TRUE)[1] print(paste0(&quot;The frequency of flowers with 15 petals is: &quot;, PetalFreq)) ## [1] &quot;The frequency of flowers with 15 petals is: 9&quot; 3.1.3 Proportions A proportion is the fraction of counts over the total sample. # Find the proportion of flowers with 15 petals TotalSample &lt;- length(Petals) PetalProp &lt;- PetalFreq/TotalSample print(paste0(&quot;The proportion of flowers with 15 petals is: &quot;, PetalProp)) ## [1] &quot;The proportion of flowers with 15 petals is: 0.3&quot; 3.1.4 Percentage A proportion can be turned into a percentage by multiplying the proportion by 100. # Find the percentage of flowers with 15 petals PetalPerc &lt;- PetalProp * 100 print(paste0(&quot;The percentage of flowers with 15 petals is: &quot;, PetalPerc, &quot;%&quot;)) ## [1] &quot;The percentage of flowers with 15 petals is: 30%&quot; 3.1.5 Histogram A histogram is a graphical representation of the distribution of data, discrete intervals (bins) are decided upon to form widths for our boxes. R has the hist() function to make basic histograms. Here are some very simple examples. # Create a histogram with a bin size of 2 hist(Petals, breaks = (length(Petals)/2), col = &quot;blue&quot;) # Create a histogram with a bin size of 5 bins &lt;- c(10,15,20,25,30) #hist(Petals, breaks = (length(Petals)/5)) hist(Petals, breaks = bins, col = &quot;orange&quot;) 3.1.6 Skew Positive Skew - A positive skew is when outliers are present along the right most end of the distribution. The histogram for Petals is an example of a positive skew Negative Skew - A negative skew is when outliers are present along the left most end of the distribution 3.2 Lesson 4 Variability In this exercise we will start by looking at the variability of our dataset. All definitions and data come from the original Udacity lesson and can be found here. 3.2.1 Data We start by assigning data to income and looking at the summary statistics. I am also going to grab all of the stats to use for labels. income &lt;- c(2500, 3000, 2900 ,2650, 3225, 2700 ,2740, 3000, 3400 ,2500, 3100, 2700) summary(income) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2500 2688 2820 2868 3025 3400 #names(income_stats) Income_min &lt;- min(income) Income_max &lt;- max(income) Income_med &lt;- median(income) Income_lowQ &lt;- unname(quantile(income, c(0.25))) Income_highQ &lt;- unname(quantile(income, c(0.75))) 3.2.2 Interquartile range The Interquartile range (IQR) is the distance between the 1st quartile and 3rd quartile and gives us the range of the middle 50% of our data. The IQR is easily found by computing: Q3 - Q1 3.2.3 Box Plot A good way to view this is using a box plot. The IQR will be displayed within the box between Q1 and Q3. boxplot(income, col = &quot;lightblue&quot;) text(x = .75,y = Income_min, labels = &quot;min&quot;) text(x = .75,y = Income_max, labels = &quot;max&quot;) text(x = .75,y = Income_med, labels = &quot;median&quot;) text(x = .75,y = Income_lowQ, labels = &quot;Q1&quot;) text(x = .75,y = Income_highQ, labels = &quot;Q3&quot;) 3.2.4 Outliers You can use the IQR to identify outliers: Upper outliers: Q3 + (1.5 * IQR) Lower outliers: Q1 - (1.5 * IQR) IQR &lt;- Income_highQ - Income_lowQ upper_outlier &lt;- Income_highQ + (1.5 * IQR) lower_outlier &lt;- Income_lowQ - (1.5 * IQR) cat(paste0(&quot;The Income IQR = $&quot;,IQR,&quot;\\n&quot;, &quot;Upper Outliers are above: $&quot;, upper_outlier,&quot;\\n&quot;, &quot;Lower Outliers are below: $&quot;,lower_outlier)) ## The Income IQR = $337.5 ## Upper Outliers are above: $3531.25 ## Lower Outliers are below: $2181.25 3.2.5 Variance The variance is the average of the squared differences from the mean. The formula for computing variance is: \\[\\sigma^{2} = \\frac{\\sum_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^{2}} {n-1}\\] # first let&#39;s calculate it from scratch # get the mean of income s_mean &lt;- mean(income) # get the difference between each income and the mean r_diff &lt;- function(x){x - s_mean} diff_of_mean &lt;- r_diff(income) # get the sqr_root of each data point sqr_of_diff &lt;- diff_of_mean^2 #sum the squares sum_sqrs &lt;- sum(sqr_of_diff) # Divide by the number of samples - 1 Var_income &lt;- sum_sqrs / (length(income) - 1) print(paste0(&quot;The variance caluclated by hand: &quot;, Var_income)) ## [1] &quot;The variance caluclated by hand: 81033.9015151515&quot; # we can also use the built in function in R print(paste0(&quot;The variance using the R built in function: &quot;,var(income))) ## [1] &quot;The variance using the R built in function: 81033.9015151515&quot; 3.2.6 Standard Deviation The standard deviation is the square root of the variance and is used to measure distance from the mean. In a normal distribution 65% of the data lies within 1 standard deviation from the mean,95% within 2 standard deviations, and 99.7% within 3 standard deviations. std_income &lt;- round(sqrt(Var_income),2) print(paste0(&quot;The standard deviation caluclated by hand: &quot;, std_income)) ## [1] &quot;The standard deviation caluclated by hand: 284.66&quot; # we can also use the built in function in R print(paste0(&quot;The standard deviation using the R built in function: &quot;,round(sd(income),2))) ## [1] &quot;The standard deviation using the R built in function: 284.66&quot; pos_1_std &lt;- s_mean + std_income pos_2_std &lt;- s_mean + std_income * 2 neg_1_std &lt;- s_mean - std_income neg_2_std &lt;- s_mean - std_income * 2 Let’s visualize this. I add in lines for one and two standard deviations but, because the data are not normal the standard deviations fall outside of the ranges defined by the three sigma rule of thumb. hist(income, probability = TRUE, col = &quot;orange&quot;) lines(density(income)) abline(v = s_mean, col = &quot;blue&quot;, ) abline(v = pos_1_std, col=&quot;blue&quot;, lty = &quot;dashed&quot;) abline(v = neg_1_std, col=&quot;blue&quot;, lty = &quot;dashed&quot;) abline(v = pos_2_std, col=&quot;red&quot;, lty = &quot;dashed&quot;) abline(v = neg_2_std, col=&quot;red&quot;, lty = &quot;dashed&quot;) text(s_mean - 20,.0015, expression(mu)) text(pos_1_std - 40,.0015, expression(mu + sigma)) text(neg_1_std - 40,.0015, expression(mu - sigma)) text(pos_2_std - 40,.0015, expression(mu + 2*sigma)) 3.3 Lesson 6 Normal Distribution In this exercise we will find the probability of a given observation within a normal distribution. All definitions and data come from the original Udacity lesson and can be found here. #install.packages(&quot;ggfortify&quot;) #library(ggfortify) 3.3.1 Probability Distribution Function. The probability distribution function is a normal curve with an area of 1 beneath it, to represent the cumulative frequency of values. 3.3.1.1 Data mean=1.85; sd=.15 lb=1.7; ub=2 #generate student heights x &lt;- seq(-4,4,length=100)*sd + mean hx &lt;- dnorm(x,mean,sd) 3.3.1.2 Create a density plot plot(x, hx, type=&quot;n&quot;, xlab=&quot;Student Height Values&quot;, ylab=&quot;Density&quot;, main=&quot;Probability Distribution&quot;) lines(x, hx) polygon(c(lb,x,ub), c(0,hx,0), col=&quot;blue&quot;) 3.3.2 Finding the probability If given an observation, you can find the probability and show the area below, above, and between particular observations. To do this you must first calculated the z-score 3.3.2.1 Z-Score \\[ z=\\frac{x-\\mu}{\\sigma}\\] The z-score is calculated by taking the observation minus the mean and dividing by the standard deviation. If given an observation of 2.05 meters the z-score would be calculated as follows: obs1 &lt;- 2.05 obs1_zscore &lt;- round((obs1 - mean)/sd, 2) print(paste0(&quot;The Z-Score for a student with the Height of 2.05 meters is: &quot;, obs1_zscore)) ## [1] &quot;The Z-Score for a student with the Height of 2.05 meters is: 1.33&quot; 3.3.2.2 Proportion using a z-table From this we know that a height of 2.05 is 1.33 standard deviations away from the mean. With this information we can use a z-table to determine the proportion of students that are shorter than this. The z-table can be found here. From the z-table we get a proportion of .9082 or 90.82 percent. A person with the height of 2.05 is taller than 90.82 percent of the students. We can calculate this in R using the pnorm function. It will give a more exact number than when using the table. 3.3.2.3 Proportion using pnorm #you can also use pnorm to get the proportion rather than looking it up in a z-table obs1_spor &lt;- round(pnorm(obs1, mean, sd),4) print(paste0(&quot;The proportion of students shorter than 2.05 meters is: &quot;, obs1_spor)) ## [1] &quot;The proportion of students shorter than 2.05 meters is: 0.9088&quot; 3.3.2.4 Plotting the percentage By multiplying the proportion by 100 you can get the percentage of students that are shorter than 2.05 meters. You can also find the percentage of students that are taller than 2.05 meters by subtracting the proportion from 1. # a plot of the data plot(x, hx, type=&quot;n&quot;, xlab=&quot;Student Height Values&quot;, ylab=&quot;Density&quot;, main=&quot;Percentage above and below 2.05 meters&quot;) # to plot the proportion I grab the samples that are above and below the observation. i &lt;- x &lt;= obs1 o &lt;- x &gt;= obs1 lines(x, hx) # I use the gathered high and low observations to make polygons showing the area. polygon(c(lb,x[i],obs1), c(0,hx[i],0), col=&quot;blue&quot;) polygon(c(obs1,x[o],ub), c(0,hx[o],0), col=&quot;yellow&quot;) #label the percentage taller_obs1 &lt;- round((1 - obs1_spor) * 100, 2) shorter_obs1 &lt;- obs1_spor * 100 text(1.8,.3, labels = shorter_obs1, col = &quot;white&quot;) text(2.1,.3, labels = taller_obs1, col = &quot;blue&quot;) 3.3.2.5 Proportion of a range You can find the proportion of students that fall between a given range by subtraction the proportion of the first observation from the proportion of the second observation. obs2 &lt;- 1.87 obs2_spor &lt;- round(pnorm(obs2, mean, sd),4) # a plot of the data plot(x, hx, type=&quot;n&quot;, xlab=&quot;Student Height Values&quot;, ylab=&quot;Density&quot;, main=&quot;Percentage between 1.87 and 2.05 meters&quot;) # to plot the proportion I grab the samples that are between the observations. i_diff &lt;- x &gt;= obs2 &amp; x &lt;= obs1 lines(x, hx) # I use the gathered range of observations to make polygons showing the area. polygon(c(obs2,x[i_diff],obs1), c(0,hx[i_diff],0), col=&quot;blue&quot;) #label the percentage between_obs &lt;- round((obs1_spor - obs2_spor) * 100, 2) text(1.95,.3, labels = between_obs, col = &quot;white&quot;) "]
]
